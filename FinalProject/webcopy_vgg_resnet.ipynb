{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Flatten,Dropout,BatchNormalization, Conv2D, Input, Activation, MaxPooling2D, ZeroPadding2D\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "import tensorflow.keras\r\n",
    "from tensorflow.keras.layers import add"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# create model\r\n",
    "input_img = Input(shape=(224, 224, 3), name='main_input')\r\n",
    "\r\n",
    "#VGG Net\r\n",
    "x1 = Conv2D(64, (3, 3))(input_img)\r\n",
    "x1 = Activation('relu')(x1)\r\n",
    "x1 = Conv2D(64, (3, 3))(x1)\r\n",
    "x1 = Activation('relu')(x1)\r\n",
    "x1 = MaxPooling2D()(x1)\r\n",
    "x1 = Conv2D(64, (3, 3))(x1)\r\n",
    "x1 = Activation('relu')(x1)\r\n",
    "x1 = Conv2D(64, (3, 3))(x1)\r\n",
    "x1 = Activation('relu')(x1)\r\n",
    "x1 = MaxPooling2D()(x1)\r\n",
    "x1 = Conv2D(64, (3, 3))(x1)\r\n",
    "x1 = Activation('relu')(x1)\r\n",
    "x1 = MaxPooling2D()(x1)\r\n",
    "x1 = Flatten()(x1)\r\n",
    "x1 = Dense(256)(x1)\r\n",
    "x1 = BatchNormalization()(x1)\r\n",
    "x1 = Activation('relu')(x1)\r\n",
    "x1 = Dense(256)(x1)\r\n",
    "x1 = BatchNormalization()(x1)\r\n",
    "x1 = Activation('relu')(x1)\r\n",
    " \r\n",
    "#Res Net\r\n",
    "x = Conv2D(64, (3, 3))(input_img)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = Activation('relu')(x)\r\n",
    "x = (ZeroPadding2D((1,1)))(x)\r\n",
    "x = Conv2D(64, (3, 3))(input_img)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = Activation('relu')(x)\r\n",
    "x = Conv2D(1, (3, 3))(input_img)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = Activation('relu')(x)\r\n",
    "x = (ZeroPadding2D((1,1)))(x)\r\n",
    "x = add([x, input_img])\r\n",
    "x = Flatten()(x)\r\n",
    "x = Dense(256)(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = Activation('relu')(x)\r\n",
    "x = Dense(256)(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = Activation('relu')(x)\r\n",
    " \r\n",
    "x = tensorflow.keras.layers.concatenate([x1, x])\r\n",
    "print(type(x))\r\n",
    "out = Dense(1, activation='sigmoid')(x)\r\n",
    " \r\n",
    "# Compile model\r\n",
    "model = Model(inputs=input_img, outputs=out)\r\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.trainable = False\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 222, 222, 64) 1792        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 222, 222, 64) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 220, 220, 64) 36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 220, 220, 64) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 110, 110, 64) 0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 108, 108, 64) 36928       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 108, 108, 64) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 106, 106, 64) 36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 106, 106, 64) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 222, 222, 1)  28          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 53, 53, 64)   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 222, 222, 1)  4           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 51, 51, 64)   36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 222, 222, 1)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 51, 51, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 224, 224, 1)  0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 64)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 224, 224, 3)  0           zero_padding2d_3[0][0]           \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 40000)        0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 150528)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          10240256    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          38535424    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 256)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          65792       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           activation_16[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            513         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 49,061,409\n",
      "Trainable params: 0\n",
      "Non-trainable params: 49,061,409\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "###########################################################\r\n",
    "# 데이터 전처리\r\n",
    "###########################################################\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \r\n",
    "\r\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # 모든 이미지를 1/255로 스케일을 조정합니다\r\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "train_dir = \"./dataset/train2\"\r\n",
    "validation_dir = './dataset/vali2'\r\n",
    "\r\n",
    "batch_size = 16\r\n",
    "# batch_size = 64\r\n",
    "\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory( \\\r\n",
    "        train_dir,                  # 타깃 디렉터리\r\n",
    "        target_size=(224, 224),     # 모든 이미지를 224 × 224 크기\r\n",
    "        batch_size=batch_size,\r\n",
    "        class_mode='binary')        #\r\n",
    "\r\n",
    "validation_generator = test_datagen.flow_from_directory(\r\n",
    "        validation_dir,\r\n",
    "        target_size=(224, 224),\r\n",
    "        batch_size=batch_size,\r\n",
    "        class_mode='binary')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 802 images belonging to 2 classes.\n",
      "Found 286 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for data_batch, labels_batch in train_generator:\r\n",
    "    print('배치 데이터 크기:', data_batch.shape)  #(20, 150, 150, 3)\r\n",
    "    print('배치 레이블 크기:', labels_batch.shape) #(20,)\r\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "배치 데이터 크기: (16, 224, 224, 3)\n",
      "배치 레이블 크기: (16,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "steps_per_epochs = 50 # 학습데이터의 총 개수 / 배치 사이즈 (소수점 올림)\r\n",
    "epochs = 30\r\n",
    "\r\n",
    "history = model.fit(\r\n",
    "      train_generator ,\r\n",
    "      steps_per_epoch=steps_per_epochs  ,\r\n",
    "      epochs=epochs ,\r\n",
    "      validation_data=validation_generator,\r\n",
    "      validation_steps=18)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 23s 310ms/step - loss: 0.4589 - accuracy: 0.7913 - val_loss: 1.0040 - val_accuracy: 0.5280\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 12s 247ms/step - loss: 0.1971 - accuracy: 0.9224 - val_loss: 1.2284 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 13s 249ms/step - loss: 0.0956 - accuracy: 0.9771 - val_loss: 1.3686 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0592 - accuracy: 0.9809 - val_loss: 1.5899 - val_accuracy: 0.4755\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 13s 259ms/step - loss: 0.0306 - accuracy: 0.9962 - val_loss: 1.3246 - val_accuracy: 0.4965\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 13s 259ms/step - loss: 0.0694 - accuracy: 0.9746 - val_loss: 2.5669 - val_accuracy: 0.4755\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 13s 260ms/step - loss: 0.0754 - accuracy: 0.9720 - val_loss: 1.9964 - val_accuracy: 0.5245\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 13s 260ms/step - loss: 0.0558 - accuracy: 0.9809 - val_loss: 1.4958 - val_accuracy: 0.5769\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 13s 261ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 5.1580 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 13s 264ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 1.3354 - val_accuracy: 0.6364\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 13s 262ms/step - loss: 0.0599 - accuracy: 0.9784 - val_loss: 1.0692 - val_accuracy: 0.6259\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0469 - accuracy: 0.9873 - val_loss: 6.6729 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0237 - accuracy: 0.9949 - val_loss: 0.9638 - val_accuracy: 0.6993\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 14s 270ms/step - loss: 0.0149 - accuracy: 0.9924 - val_loss: 1.2742 - val_accuracy: 0.4860\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0880 - accuracy: 0.9707 - val_loss: 7.8797 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 14s 268ms/step - loss: 0.0275 - accuracy: 0.9949 - val_loss: 1.6244 - val_accuracy: 0.5734\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 14s 268ms/step - loss: 0.0483 - accuracy: 0.9822 - val_loss: 1.6287 - val_accuracy: 0.6294\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 14s 270ms/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 3.0136 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 14s 269ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 1.9240 - val_accuracy: 0.5035\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 14s 269ms/step - loss: 0.0045 - accuracy: 0.9975 - val_loss: 1.7578 - val_accuracy: 0.4930\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 1.8984 - val_accuracy: 0.5455\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 0.0183 - accuracy: 0.9925 - val_loss: 2.2195 - val_accuracy: 0.5280\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0505 - accuracy: 0.9860 - val_loss: 13.4753 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 14s 269ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 1.5627 - val_accuracy: 0.5524\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 1.0496 - val_accuracy: 0.4930\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 14s 270ms/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 2.3395 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 14s 270ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 2.1510 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 6.8290 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 14s 270ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 4.8645 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 13s 268ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 1.1539 - val_accuracy: 0.5455\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model.save(\"./tn_model/vgg_res_v4.h5\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Program Files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "435c7524b81c754d2a38f9b1930a50d7a83318eec9a7b6faab8c4b8cfd59b603"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}