<!DOCTYPE html>
<html lang="ko">

<head>
    <meta charset="UTF-8">
    <!-- Required meta tags -->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
        integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/earlyaccess/notosanskr.css">
    <title>Stop The TurtleNeck</title>
    <link rel="stylesheet" href="style.css">
</head> 
<body>
    <div class="container mt-5">
        <div class="frame">
            <div class="center">
                <div class="headline">
                    <div class="small">거북목</div>패널티
                </div>
                <p>거북목 60초</p><p><strong>-1000점</strong></p>
                <div class="circle-big">
                    <div class="text">
                        <span id="counter">10,000</span><div class="small">점</div>
                        <div class="small" style="margin: 20px auto;">거북목</div><span id="timestamp" >0</span><div class="small"></div>
                        
                    </div>
                    <svg>
                        <circle class="bg" cx="57" cy="57" r="52" />
                    </svg>
                </div>
            </div>
        </div>
        <h1>거북목 멈춰!</h1>
        <button class="btn btn-primary"type="button" onclick="init()">Start</button>
        <button id="stopbtn" class="btn btn-primary"type="button">Stop</button>
        <div><canvas id="canvas" style="margin: 50px auto;"></canvas></div>
        
        <div id="label-container"></div>
        <img src="head_shoulder_guideline.png" id="head_shoulder_line_img" style="display:none">
    </div>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
        integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
        integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">
        // More API functions here:
        // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose

        // the link to your model provided by Teachable Machine export panel
        const URL = "https://teachablemachine.withgoogle.com/models/Z7ObjYThE/";  
        let model, webcam, ctx, labelContainer, maxPredictions;
        let status = "";
        let st_status = "";
        let count = 10_000;
        let start_count = 0;
        let after_count = 0;
        
        async function init() {
            
            // const modelURL = URL + "model.json";
            const modelURL = "../tn_model/out_put/model.json";
            const metadataURL = URL + "metadata.json";

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // Note: the pose library adds a tmPose object to your window (window.tmPose)
            model = await tmImage.load(modelURL, metadataURL);
            
            maxPredictions = model.getTotalClasses();

            // Convenience function to setup a webcam
            const size = 500;
            const flip = true; // whether to flip the webcam
            webcam = new tmImage.Webcam(size, size, flip); // width, height, flip
            await webcam.setup(); // request access to the webcam
            await webcam.play();
            window.requestAnimationFrame(loop);
            

            // append/get elements to the DOM
            
            const canvas = document.getElementById("canvas");
            canvas.width = size; canvas.height = size;
            ctx = canvas.getContext("2d");
            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
            }
        
        // async function start_predict(){
        //     const st_pred = await model.predict(webcam.canvas);
        //     if (st_pred[0].probability.toFixed(2) == 1.00){
        //         status = st_pred[0].className;
        //         return status;
        //     } else {
        //         status = st_pred[1].className;
        //         return stauts;
        //     }
        // }
            // if (st_staus == "corr"){
            //     const co_audio = new Audio('1.mp3');
            //     co_audio.play();
            // } else if (st_status == "forw"){
            //     const fo_audio = new Audio('result1.mp3');
            //     fo_audio.play();
            //     $("#timestamp").html(after_count);
            // }  
            
        // async function aa(){
        //     let ss = await start_predict()
        //     console.log("s = ", ss)
        // }
        // aa()

        async function loop(timestamp) {
            webcam.update(); // update the webcam frame
            await predict(); 
            window.requestAnimationFrame(loop);
        }
        
        async function predict() {
            // Prediction #1: run input through posenet
            // estimatePose can take in an image, video or canvas html element
            // Prediction 2: run input through teachable machine classification model
            const prediction = await model.predict(webcam.canvas);
            console.log(prediction[0].probability)
           
            if (prediction[0].probability < 0.5) {
                if (status == "corr") {
                const corr_audio = new Audio('0.mp3');
                console.log(0);
                corr_audio.play();
                
                }
                status = "forw";
                
            } else if (prediction[0].probability > 0.5) {
                if(status == "forw"){
                const forw_audio = new Audio('result1.mp3');
                after_count += 1;
                count -= 1000;
                forw_audio.play();
                $("#counter").html(count);
                $("#timestamp").html(after_count);
                
            }
                status = "corr";
                
            } else {
                status = "";
            }
              
            if ( count <= 0){
                    count = 0;
                    $('#counter').html(count);
            }
            for (let i = 0; i < maxPredictions; i++) {
                const classPrediction =
                    prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                labelContainer.childNodes[i].innerHTML = classPrediction;
            }
            if (webcam.canvas) {
            ctx.drawImage(webcam.canvas, 0, 0);
            var line_img = document.getElementById("head_shoulder_line_img")		
					ctx.drawImage(
						line_img,
						0,
						0,
						webcam.canvas.width,
						webcam.canvas.height
					);
            }
        }
    }

        
        
        
    
    
            

    const stopbtn = document.getElementById("stopbtn")
        stopbtn.addEventListener("click", stop)
        async function stop(){
            webcam.stop();
            
        }
        
        
    </script>

</body>

</html>